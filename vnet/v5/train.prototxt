layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "label"
  python_param {
    module: "VnetDataLayer"
    layer: "VnetDataLayer"
    param_str: "{\'vol_size\': 64, \'iter_count\': 100000, \'rotate_ratio\': 0.9, \'queue_size\': 30, \'phase\': \'train\', \'data_path\': \'d:/project/tianchi/data/\', \'shift_ratio\': 0.9, \'histogram_shift_ratio\': 0.9, \'net_path\': \'v5/\', \'batch_size\': 4}"
  }
}

# input

layer {
  name: "conv_i64c16o32_input_1"
  type: "Convolution"
  bottom: "data"
  top: "conv_i64c64o32_input_1"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 16
    kernel_size: 2
    pad: 0
    stride: 2
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

#layer {
#  name: "relu_i64c32o64_input_1"
#  type: "PReLU"
#  bottom: "conv_i64c32o64_input_1"
#  top: "relu_i64c32o64_input_1"
#}

# Create 16 channel data for residual function

# layer {
#   name: "split_input"
#   type: "Split"
#   bottom: "data"
#   top: "split_input_1"
#   top: "split_input_2"
#   top: "split_input_3"
#   top: "split_input_4"
#   top: "split_input_5"
#   top: "split_input_6"
#   top: "split_input_7"
#   top: "split_input_8"
#   top: "split_input_9"
#   top: "split_input_10"
#   top: "split_input_11"
#   top: "split_input_12"
#   top: "split_input_13"
#   top: "split_input_14"
#   top: "split_input_15"
#   top: "split_input_16"
# }

# Concat into channel

# layer {
#   name: "concat_input"
#   type: "Concat"
#   bottom: "split_input_1"
#   bottom: "split_input_2"
#   bottom: "split_input_3"
#   bottom: "split_input_4"
#   bottom: "split_input_5"
#   bottom: "split_input_6"
#   bottom: "split_input_7"
#   bottom: "split_input_8"
#   bottom: "split_input_9"
#   bottom: "split_input_10"
#   bottom: "split_input_11"
#   bottom: "split_input_12"
#   bottom: "split_input_13"
#   bottom: "split_input_14"
#   bottom: "split_input_15"
#   bottom: "split_input_16"
#   top: "concat_input"
#   concat_param { axis: 1 }
# }

layer {
  name: "conv_i32c64o32_input_2"
  type: "Convolution"
  bottom: "conv_i64c16o32_input_1"
  top: "conv_i32c64o32_input_2"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "bn_input_2"
  type: "BatchNorm"
  bottom: "conv_i32c64o32_input_2"
  top: "bn_input_2"
}

layer {
  name: "relu_input_2"
  type: "PReLU"
  bottom: "bn_input_2"
  top: "relu_input_2"
}

layer {
  name: "conv_i32c64o32_input_3"
  type: "Convolution"
  bottom: "relu_input_2"
  top: "conv_i32c64o32_input_3"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "bn_input_3"
  type: "BatchNorm"
  bottom: "conv_i32c64o32_input_3"
  top: "bn_input_3"
}

layer {
  name: "relu_input_3"
  type: "PReLU"
  bottom: "bn_input_3"
  top: "relu_input_3"
}

layer {
  name: "conv_i32c64o32_input_4"
  type: "Convolution"
  bottom: "relu_input_3"
  top: "conv_i32c64o32_input_4"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "bn_input_4"
  type: "BatchNorm"
  bottom: "conv_i32c64o32_input_4"
  top: "bn_input_4"
}

layer {
  name: "add_input"
  type: "Eltwise"
  bottom: "conv_i64c64o32_input_1"
  bottom: "bn_input_4"
  top: "add_input"
  eltwise_param { operation: SUM }
}

layer {
  name: "relu_add_input"
  type: "PReLU"
  bottom: "add_input"
  top: "relu_add_input"
}

# pooling

layer {
  name: "conv_pooling_i32c128o16"
  type: "Convolution"
  bottom: "relu_add_input"
  top: "conv_pooling_i32c128o16"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 128
    kernel_size: 2
    pad: 0
    stride: 2
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

#layer {
#  name: "relu_pooling_i64c32o32"
#  type: "PReLU"
#  bottom: "conv_pooling_i64c32o32"
#  top: "relu_pooling_i64c32o32"
#}

# vally

layer {
  name: "conv_i16c128o16_vally_1"
  type: "Convolution"
  bottom: "conv_pooling_i32c128o16"
  top: "conv_i16c128o16_vally_1"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "bn_vally_1"
  type: "BatchNorm"
  bottom: "conv_i16c128o16_vally_1"
  top: "bn_vally_1"
}

layer {
  name: "relu_vally_1"
  type: "PReLU"
  bottom: "bn_vally_1"
  top: "relu_vally_1"
}

layer {
  name: "conv_i16c128o16_vally_2"
  type: "Convolution"
  bottom: "relu_vally_1"
  top: "conv_i16c128o16_vally_2"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "bn_vally_2"
  type: "BatchNorm"
  bottom: "conv_i16c128o16_vally_2"
  top: "bn_vally_2"
}

layer {
  name: "relu_vally_2"
  type: "PReLU"
  bottom: "bn_vally_2"
  top: "relu_vally_2"
}

layer {
  name: "conv_i16c128o16_vally_3"
  type: "Convolution"
  bottom: "relu_vally_2"
  top: "conv_i16c128o16_vally_3"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "bn_vally_3"
  type: "BatchNorm"
  bottom: "conv_i16c128o16_vally_3"
  top: "bn_vally_3"
}

layer {
  name: "add_vally"
  type: "Eltwise"
  bottom: "conv_pooling_i32c128o16"
  bottom: "bn_vally_3"
  top: "add_vally"
  eltwise_param { operation: SUM }
}

layer {
  name: "relu_add_vally"
  type: "PReLU"
  bottom: "add_vally"
  top: "relu_add_vally"
}

# depooling

layer {
  name: "deconv_depooling_i16c128o32"
  type: "Deconvolution"
  bottom: "relu_add_vally"
  top: "deconv_depooling_i16c128o32"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 128
    kernel_size: 2
    pad: 0
    stride: 2
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "conv_depooling_i32c64o32"
  type: "Convolution"
  bottom: "deconv_depooling_i16c128o32"
  top: "conv_depooling_i32c64o32"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 64
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

#layer {
#  name: "relu_depooling_i32c16o64"
#  type: "PReLU"
#  bottom: "deconv_depooling_i32c16o64"
#  top: "relu_depooling_i32c16o64"
#}

# output

layer {
  name: "concat_output"
  type: "Concat"
  bottom: "relu_add_input"
  bottom: "conv_depooling_i32c64o32"
  top: "concat_output"
  concat_param { axis: 1 }
}

layer {
  name: "conv_concat_i32c64o32"
  type: "Convolution"
  bottom: "concat_output"
  top: "conv_concat_i32c64o32"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 64
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "conv_i32c64o32_output_1"
  type: "Convolution"
  bottom: "conv_concat_i32c64o32"
  top: "conv_i32c64o32_output_1"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "bn_output_1"
  type: "BatchNorm"
  bottom: "conv_i32c64o32_output_1"
  top: "bn_output_1"
}

layer {
  name: "relu_output_1"
  type: "PReLU"
  bottom: "bn_output_1"
  top: "relu_output_1"
}

layer {
  name: "conv_i32c64o32_output_2"
  type: "Convolution"
  bottom: "relu_output_1"
  top: "conv_i32c64o32_output_2"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "bn_output_2"
  type: "BatchNorm"
  bottom: "conv_i32c64o32_output_2"
  top: "bn_output_2"
}

layer {
  name: "relu_output_2"
  type: "PReLU"
  bottom: "bn_output_2"
  top: "relu_output_2"
}

layer {
  name: "conv_i32c64o32_output_3"
  type: "Convolution"
  bottom: "relu_output_2"
  top: "conv_i32c64o32_output_3"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "bn_output_3"
  type: "BatchNorm"
  bottom: "conv_i32c64o32_output_3"
  top: "bn_output_3"
}

layer {
  name: "add_output"
  type: "Eltwise"
  bottom: "conv_concat_i32c64o32"
  bottom: "bn_output_3"
  top: "add_output"
  eltwise_param { operation: SUM }
}

layer {
  name: "relu_add_output"
  type: "PReLU"
  bottom: "add_output"
  top: "relu_add_output"
}

# 1 * 1 * 1 conv

layer {
  name: "conv_i32c2o32_output_4"
  type: "Convolution"
  bottom: "relu_add_output"
  top: "conv_i32c2o32_output_4"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0.0 }
  convolution_param {
    engine: CUDNN
    num_output: 2
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler { type: "msra" variance_norm: 2 }
    bias_filler { type: "constant" value: 0.0 }
  }
}

layer {
  name: "relu_output"
  type: "ReLU"
  bottom: "conv_i32c2o32_output_4"
  top: "relu_output"
}

layer {
  name: "reshape_output"
  type: "Reshape"
  bottom: "relu_output"
  top: "reshape_output"
  reshape_param {
    shape {
      dim: 0  # copy the dimension from below
      dim: 2
      dim: -1 # this should be 32768
    }
  }
}

layer {
  name: "reshape_label"
  type: "Reshape"
  bottom: "label"
  top: "reshape_label"
  reshape_param {
    shape {
      dim: 0  # copy the dimension from below
      dim: 1
      dim: -1 # this should be 32768
    }
  }
}

layer {
  name: "softmax_output"
  type: "Softmax"
  bottom: "reshape_output"
  top: "softmax_output"
}

layer {
  type: "DiceLoss"
  name: "loss"
  top: "loss"
  bottom: "softmax_output"
  bottom: "reshape_label"
}
